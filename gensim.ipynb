{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T04:45:38.702084Z",
     "start_time": "2019-06-01T04:45:37.056433Z"
    }
   },
   "outputs": [],
   "source": [
    "import thulac\n",
    "import jieba\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T04:45:44.681329Z",
     "start_time": "2019-06-01T04:45:38.722915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n"
     ]
    }
   ],
   "source": [
    "Loc=thulac.thulac()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n/名词 np/人名 ns/地名 ni/机构名 nz/其它专名\n",
    "m/数词 q/量词 mq/数量词 t/时间词 f/方位词 s/处所词\n",
    "v/动词 a/形容词 d/副词 h/前接成分 k/后接成分 i/习语 \n",
    "j/简称 r/代词 c/连词 p/介词 u/助词 y/语气助词\n",
    "e/叹词 o/拟声词 g/语素 w/标点 x/其它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T07:52:36.289705Z",
     "start_time": "2019-06-01T07:52:36.205874Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "深夜 t 0 2\n",
      "的 u 2 3\n",
      "穆赫兰道 nz 3 7\n",
      "发生 v 7 9\n",
      "一 m 9 10\n",
      "桩 q 10 11\n",
      "车祸 n 11 13\n",
      "， w 13 14\n",
      "女子 n 14 16\n",
      "丽塔 n 16 18\n",
      "在 p 18 19\n",
      "车祸 n 19 21\n",
      "中 f 21 22\n",
      "失忆 v 22 24\n",
      "了 u 24 25\n"
     ]
    }
   ],
   "source": [
    "#编写的thulac的切分词函数，得到词，标签，起始位置和结束位置\n",
    "def tokenize_thu(unicode_sentence):\n",
    "    \n",
    "    \"\"\"\n",
    "    Tokenize a sentence and yields tuples of (word, tag, start, end)\n",
    "    Parameter:\n",
    "        - sentence: the str(unicode) to be segmented.\n",
    "    \"\"\"\n",
    "    start = 0\n",
    "    for i in Loc.cut(unicode_sentence):\n",
    "        w = i[0]\n",
    "        tag = i[1]\n",
    "        width = len(w)\n",
    "        yield (w, tag, start, start + width)\n",
    "        start += width\n",
    "        \n",
    "#example\n",
    "\n",
    "a=tokenize_thu('2010年4月20日首次在江苏省如东太阳岛以东海域发现零星漂浮浒苔。')\n",
    "#a=tokenize_thu('深夜的穆赫兰道发生一桩车祸，女子丽塔在车祸中失忆了')\n",
    "for i,j,k,l in a:\n",
    "    print(i,j,k,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:31:14.996589Z",
     "start_time": "2019-05-31T07:30:44.232740Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:32:25.176874Z",
     "start_time": "2019-05-31T07:32:25.166427Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = [['human', 'interface', 'computer'],\n",
    " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    " ['eps', 'user', 'interface', 'system'],\n",
    " ['system', 'human', 'system', 'eps'],\n",
    " ['user', 'response', 'time'],\n",
    " ['trees'],\n",
    " ['graph', 'trees'],\n",
    " ['graph', 'minors', 'trees'],\n",
    " ['graph', 'minors', 'survey']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:33:17.285088Z",
     "start_time": "2019-05-31T07:33:17.278143Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:33:25.332353Z",
     "start_time": "2019-05-31T07:33:25.325904Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",              \n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:33:59.960054Z",
     "start_time": "2019-05-31T07:33:59.949143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "\n",
    "from pprint import pprint  # pretty-printer\n",
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:35:26.812016Z",
     "start_time": "2019-05-31T07:35:26.805568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "#dictionary.save(os.path.join(TEMP_FOLDER, 'deerwester.dict'))  # store the dictionary, for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:35:56.118026Z",
     "start_time": "2019-05-31T07:35:56.110586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:37:19.172995Z",
     "start_time": "2019-05-31T07:37:19.165524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)  # the word \"interaction\" does not appear in the dictionary and is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:49:55.677300Z",
     "start_time": "2019-05-31T07:49:55.670852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n",
      "[(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "[(2, 1), (5, 1), (7, 1), (8, 1)]\n",
      "[(1, 1), (5, 2), (8, 1)]\n",
      "[(3, 1), (6, 1), (7, 1)]\n",
      "[(9, 1)]\n",
      "[(9, 1), (10, 1)]\n",
      "[(9, 1), (10, 1), (11, 1)]\n",
      "[(4, 1), (10, 1), (11, 1)]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "#corpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER, 'deerwester.mm'), corpus)  # store to disk, for later use\n",
    "for c in corpus:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:49:56.588532Z",
     "start_time": "2019-05-31T07:49:56.582082Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "tfidf = models.TfidfModel(corpus)  # step 1 -- initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:49:59.452759Z",
     "start_time": "2019-05-31T07:49:59.445815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.7071067811865476), (1, 0.7071067811865476)]\n"
     ]
    }
   ],
   "source": [
    "doc_bow = [(0, 1), (1, 1)]\n",
    "print(tfidf[doc_bow])  # step 2 -- use the model to transform vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:49:59.928112Z",
     "start_time": "2019-05-31T07:49:59.921664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.3244870206138555)]\n",
      "[(2, 0.5710059809418182), (5, 0.4170757362022777), (7, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(1, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(3, 0.6282580468670046), (6, 0.6282580468670046), (7, 0.45889394536615247)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(4, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "for doc in corpus_tfidf:\n",
    "     print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:05:53.328089Z",
     "start_time": "2019-05-31T08:05:53.317672Z"
    }
   },
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)  # initialize an LSI transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:05:53.685105Z",
     "start_time": "2019-05-31T08:05:53.677666Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_lsi = lsi[corpus_tfidf]  # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:05:54.075203Z",
     "start_time": "2019-05-31T08:05:54.068755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"response\" + 0.060*\"time\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
       " (1,\n",
       "  '-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:42:16.294192Z",
     "start_time": "2019-05-31T08:42:16.287744Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = ['工业互联网平台的核心技术是什么',\n",
    "            '工业现场生产过程优化场景有哪些']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:35:49.138466Z",
     "start_time": "2019-05-31T08:35:49.129537Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_cut(doc):\n",
    "    seg = [jieba.lcut(w) for w in doc]\n",
    "    return seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StopWordsList(filepath):\n",
    "    wlst = [w.strip() for w in open(filepath,'r',encoding='utf8').readlines()]\n",
    "    return wlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_flag = ['x', 'c', 'u','d', 'p', 't', 'uj', 'm', 'f', 'r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:49:47.880177Z",
     "start_time": "2019-05-31T08:49:47.873234Z"
    }
   },
   "outputs": [],
   "source": [
    "#对文本集中的文本进行中文分词，返回分词列表\n",
    "def seg_sentence(sentence,stop_words):\n",
    "    sentence_seged = jieba.cut(sentence.strip())\n",
    "    # sentence_seged = set(sentence_seged)\n",
    "    outstr = ''\n",
    "    for word in sentence_seged:\n",
    "        if word not in stop_words:\n",
    "            if word != '\\t':\n",
    "                outstr += word\n",
    "                outstr += ' '\n",
    "\n",
    "    return outstr.rstrip().split(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:55:12.171076Z",
     "start_time": "2019-05-31T08:55:12.160659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['工业', '互联网', '平台', '核心技术', '什么']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words=['的','是','也','有']\n",
    "sen='工业互联网平台的核心技术是什么'\n",
    "seg_sentence(sen,stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:55:12.901783Z",
     "start_time": "2019-05-31T08:55:12.896823Z"
    }
   },
   "outputs": [],
   "source": [
    "texts=[seg_sentence(seg,stop_words) for seg in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:55:13.463226Z",
     "start_time": "2019-05-31T08:55:13.456778Z"
    }
   },
   "outputs": [],
   "source": [
    "#2、基于文件集建立【词典】，并提取词典特征数\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "feature_cnt = len(dictionary.token2id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:55:46.742893Z",
     "start_time": "2019-05-31T08:55:46.736941Z"
    }
   },
   "outputs": [],
   "source": [
    "#3、基于词典，将【分词列表集】转换为【稀疏向量集】，也就是【语料库】\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:55:52.110559Z",
     "start_time": "2019-05-31T08:55:52.103614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:56:42.513672Z",
     "start_time": "2019-05-31T08:56:42.507225Z"
    }
   },
   "outputs": [],
   "source": [
    "#4、使用“TF-TDF模型”处理【语料库】\n",
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:36:23.756413Z",
     "start_time": "2019-05-31T08:36:23.751948Z"
    }
   },
   "outputs": [],
   "source": [
    "texts=word_cut(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:56:26.552456Z",
     "start_time": "2019-05-31T08:56:26.545018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'互联网': 0,\n",
       " '什么': 1,\n",
       " '工业': 2,\n",
       " '平台': 3,\n",
       " '核心技术': 4,\n",
       " '优化': 5,\n",
       " '哪些': 6,\n",
       " '场景': 7,\n",
       " '现场': 8,\n",
       " '生产': 9,\n",
       " '过程': 10}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##为语料库中出现的所有单词分配了一个唯一的整数id\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:37:41.142429Z",
     "start_time": "2019-05-31T08:37:41.135947Z"
    }
   },
   "outputs": [],
   "source": [
    "##该函数doc2bow()只计算每个不同单词的出现次数，将单词转换为整数单词id，并将结果作为稀疏向量返回\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:37:45.415528Z",
     "start_time": "2019-05-31T08:37:45.406105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)],\n",
       " [(2, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:39:49.616738Z",
     "start_time": "2019-05-31T08:39:49.609794Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "# train the model\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:40:20.089833Z",
     "start_time": "2019-05-31T08:40:19.906463Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-32557ea969fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
